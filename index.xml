<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>About on Bhairavi Muralidharan</title><link>/</link><description>Recent content in About on Bhairavi Muralidharan</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 20 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>Lexical Normalization System 💬</title><link>/projects/lexical/</link><pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate><guid>/projects/lexical/</guid><description>One of the most common methods of obtaining data used for NLP is through social media. This resource&amp;rsquo;s significant challenge is that the text is not traditionally accurate as it is filled with short forms and colloquial substitutes. The project&amp;rsquo;s goal was to develop a Lexical Normalization system, which enables efficient information extraction by converting non-standard text to a ready-to-use standard register.
The process involved experimenting with data augmentation methods and implementing baselines such as Maximum Frequency Replacement.</description><content>&lt;p>One of the most common methods of obtaining data used for NLP is through social media. This resource&amp;rsquo;s significant challenge is that the text is not traditionally accurate as it is filled with short forms and colloquial substitutes. The project&amp;rsquo;s goal was to develop a Lexical Normalization system, which enables efficient information extraction by converting non-standard text to a ready-to-use standard register.&lt;/p>
&lt;p>The process involved experimenting with data augmentation methods and implementing baselines such as Maximum Frequency Replacement. A final hybrid Character-based Encoder-Decoder model architecture was built that handled In-Vocab words and Out-Of-Vocab words differently. This method resulted in an increase in the accuracy by 3%, and I am currently working on scraping twitter data and categorizing words that fail spell check to improve the system&amp;rsquo;s overall efficacy.&lt;/p>
&lt;p>View the code -&amp;gt; &lt;a href="https://github.com/bhairavi-m/Lexical-Normalization">GitHub&lt;/a>&lt;/p>
&lt;p>Read the report -&amp;gt; &lt;a href="https://drive.google.com/file/d/1mgeCNgofnTRcDA8IjJxOsDkd0R_Dxgwa/view">Google Drive&lt;/a>&lt;/p>
&lt;h4 id="team">Team&lt;/h4>
&lt;p>&lt;a href="https://www.linkedin.com/in/jonasoppenheim/">Jonas Oppenheim&lt;/a> &lt;a href="https://www.linkedin.com/in/parthmsheth/">Parth Sheth&lt;/a>&lt;/p></content></item><item><title>Session-based Skip Prediction: Spotify 🎹</title><link>/projects/spotify/</link><pubDate>Sat, 20 Nov 2021 00:00:00 +0000</pubDate><guid>/projects/spotify/</guid><description>Spotify is a leading music service fuelled by its customization and music knowledge driven by algorithms to understand the way users sequentially interact with music. This project focussed on the task of session-based sequential skip prediction, i.e., predicting whether users will skip tracks, given their immediately preceding interactions in their listening session.
This project was an exciting supervised machine learning classification problem. It helped us understand intricate behavioral patterns of how users engage with tracks and which track features play an important role in prediction.</description><content>&lt;p>Spotify is a leading music service fuelled by its customization and music knowledge driven by algorithms to understand the way users sequentially interact with music. This project focussed on the task of session-based sequential skip prediction, i.e., predicting whether users will skip tracks, given their immediately preceding interactions in their listening session.&lt;/p>
&lt;p>This project was an exciting supervised machine learning classification problem. It helped us understand intricate behavioral patterns of how users engage with tracks and which track features play an important role in prediction. It was done as part of a three-member team, and we came up with two approaches: feature-based classification using boosted trees and the second dealing with sequential modeling using RNNs. I primarily worked on setting up functions in Python (using Google Colab) that performed feature-based classification using algorithms like Random Forest Classifier, XGBoost Classifier, and Logistic Classifier. I discovered that the XGBoost classifier achieved the best validation scores across all evaluation metrics. I also preprocessed the data using PCA and conducted an error analysis for the extended models using RNNs. We individually went over all stages of the pipeline (preprocessing, feature engineering, modeling), which enabled ease of collaboration in the end and helped us iterate through different methods parallelly.&lt;/p>
&lt;p>The main challenge for Spotify is to recommend the right music to each user. Hence, most of the work focuses on Recommender Systems and a little on describing how users sequentially interact with the streamed content they are presented. The outcome of our empirical analysis highlighted the importance of sequence in the prediction and how well the recommendation system is working. Our sequential modeling using RNNs increased the accuracy from 64% to 78%, and we are currently working on tuning the hyperparameters of this Char RNN model to generate more accurate results.&lt;/p>
&lt;p>View the code -&amp;gt; &lt;a href="https://github.com/bhairavi-m/Spotify-Sequential-Skip-Prediction">GitHub&lt;/a>&lt;/p>
&lt;p>Read the report -&amp;gt; &lt;a href="https://drive.google.com/file/d/1BQT-Utcb4O52bOcUdhZ3uln9xhe2022N/view">Google Drive&lt;/a>&lt;/p>
&lt;h4 id="team">Team&lt;/h4>
&lt;p>&lt;a href="https://www.linkedin.com/in/purva-sheth/">Purva Sheth&lt;/a> &lt;a href="https://www.linkedin.com/in/parthmsheth/">Parth Sheth&lt;/a>&lt;/p></content></item><item><title>Programming</title><link>/experience/programming/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>/experience/programming/</guid><description>Before pursuing the MSE in Data Science program at Penn, I worked as an Associate Data Scientist at iQGateway - an IT solutions company. I helped build a next-generation Automated Machine Learning platform that involved pipeline automation and patented model evaluation based on multiple metrics. I worked on creating a modular feature transformation library for transforming data in Python and conducted extensive research on Machine Learning. This included optimizing MLOps workflow to enable an easy transition from model development to inference for production environments.</description><content>&lt;p>Before pursuing the MSE in Data Science program at Penn, I worked as an Associate Data Scientist at iQGateway - an IT solutions company. I helped build a next-generation Automated Machine Learning platform that involved pipeline automation and patented model evaluation based on multiple metrics. I worked on creating a modular feature transformation library for transforming data in Python and conducted extensive research on Machine Learning. This included optimizing MLOps workflow to enable an easy transition from model development to inference for production environments. I not only learned how to use existing AutoML tools like Dataiku, but also used various libraries in the Python Data Science ecosystem (NumPy, pandas, scikit-learn, PyTorch - to name a few) for developing software at a professional level. Working in a collaborative environment helped me develop critical programming skills; using version control systems like GitLab highlighted the importance of good coding practices, building documentation using the sphinx library taught me the value of well-documented work, and conducting unit-tests using the pytest library maintained an agile process while establishing code standards across the development team. Additionally, I used tools that support the Data Science pipeline like Weights and Biases - an ML experiment tracking platform, to create benchmarks of different Machine Learning experiments, which aided in streamlining model debugging and tuning.&lt;/p></content></item><item><title>Data Analysis</title><link>/experience/data/</link><pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate><guid>/experience/data/</guid><description>Prior to joining the AutoML team at iQGateway, I initially worked on analyzing students&amp;rsquo; performance through data generated by a Technology-Enabled Social Learning Platform (EdTech) for a client, one of India&amp;rsquo;s leading IT service organizations. I designed and built structured staging tables using SQL to draw inferences, resulting in the automation of report generation for the platform. The preliminary Descriptive Analysis involved data cleansing, binning, and extracting data to inference tables, leading to the formation of detailed reports that contained high-value actionable insights and data visualizations.</description><content>&lt;p>Prior to joining the AutoML team at iQGateway, I initially worked on analyzing students&amp;rsquo; performance through data generated by a Technology-Enabled Social Learning Platform (EdTech) for a client, one of India&amp;rsquo;s leading IT service organizations. I designed and built structured staging tables using SQL to draw inferences, resulting in the automation of report generation for the platform. The preliminary Descriptive Analysis involved data cleansing, binning, and extracting data to inference tables, leading to the formation of detailed reports that contained high-value actionable insights and data visualizations. Performing further Exploratory Data Analysis helped me understand Business Process Models and Notations, which enabled efficient information extraction from the various entity relationships. I became adept at using MS Excel to pivot the data, making it fit for analysis. Lastly, the Inferential Analysis led to reports used as nomination collaterals for awards by the client. A notable recognition of this work was evidenced when the client won the coveted Outstanding HR initiative Award at the 2020 Global Business Excellence Awards.&lt;/p></content></item><item><title>Social Impact</title><link>/experience/social/</link><pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate><guid>/experience/social/</guid><description>Coming from a country where abject poverty is an overwhelming part of your daily life, it is difficult not to realize the privilege of having a family with stable financial means. This disheartening reality imbibed a sense of responsibility toward restoring some sort of parity. I truly believe that education has the power to break intergenerational cycles of poverty; it empowers individuals, promotes healthier lives, and boosts economic growth. I thus volunteered as a Mathematics teacher for children between the ages of 7-12 at the Center for Social Action (an organization in Christ University) during my undergraduate studies.</description><content>&lt;p>Coming from a country where abject poverty is an overwhelming part of your daily life, it is difficult not to realize the privilege of having a family with stable financial means. This disheartening reality imbibed a sense of responsibility toward restoring some sort of parity. I truly believe that education has the power to break intergenerational cycles of poverty; it empowers individuals, promotes healthier lives, and boosts economic growth. I thus volunteered as a Mathematics teacher for children between the ages of 7-12 at the Center for Social Action (an organization in Christ University) during my undergraduate studies. I believe I have the resources to unleash my potential, and thus it has been my goal to leverage my education and knowledge for the benefit of others. Being at the forefront of the digital revolution, it is exciting that I get to use technology for social welfare, to analyze and develop policies that efficiently provide the destitute section of our society the means to lead a better life.&lt;/p>
&lt;p>During the winter fest organized by the Center for Social Action in December 2018, I met Shveta Raina, who founded Talerang, a career training company working towards creating a work-ready India. Talerang’s formal research began when Shveta was a student at Harvard Business School. Her analysis of India’s best colleges found that under 60% of students felt ready to take on a job, and less than 50% of students had mentors they could seek out, this was flagged as a work-readiness crisis, and the company set out to tackle the issue. I joined Talerang as a Web Design Intern and redesigned Talerang’s Online Portal by restructuring content while understanding User Experience principles which improved content engagement by 7%. I enjoyed meeting with the students mentored by Talerang and conducting their flagship Future CEOs program. Additionally, I was appointed as President of the Bangalore City Chapter, as a result of which I hosted multiple career fairs where I honed my leadership skills and connected with people from different backgrounds. This experience helped me recognize and appreciate the vital impact of today’s youth while constantly engaging with the community.&lt;/p>
&lt;p>During my time as a Chapter President, I was left with a feeling of immense satisfaction at the end of every day. It gave my life a more defined purpose, and I woke up with a rush of excitement to do better. I acknowledge that bringing about change and making a social impact takes compounded effort and commitment along with time, and the wins are few and far between. I found the small steps we took rewarding, and I will keep pushing for them as the only way to rise above.&lt;/p></content></item><item><title/><link>/writings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/writings/</guid><description/><content>&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted --></content></item><item><title>About</title><link>/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/about/</guid><description>Hi!👋🏽 I am currently pursuing the MSE in Data Science program at the University of Pennsylvania. I completed my Bachelor’s degree in Computer Science, Mathematics and Statistics and I am passionate about Data, Ethics, Policy and Social Impact. I am eager about working on Machine Learning algorithms that would avoid undesirable biases, promote people&amp;rsquo;s best interests, be open to introspection, and aim towards building AI that behaves in a socially responsible way.</description><content>&lt;h2 id="hi">Hi!👋🏽&lt;/h2>
&lt;p>I am currently pursuing the MSE in Data Science program at the University of Pennsylvania. I completed my Bachelor’s degree in Computer Science, Mathematics and Statistics and I am passionate about Data, Ethics, Policy and Social Impact. I am eager about working on Machine Learning algorithms that would avoid undesirable biases, promote people&amp;rsquo;s best interests, be open to introspection, and aim towards building AI that behaves in a socially responsible way.&lt;/p>
&lt;h2 id="interests">Interests📝&lt;/h2>
&lt;p>Recently looking to gain a comprehensive grasp of Quantitative Social Science methods in a well-structured program with unmatchable rigor. I want to take up AI projects that deal with social impact in a fair and equitable manner. In the long term, I would like to be involved in roles where I can utilize my Data Science skills to develop innovative solutions for Social Good.&lt;/p>
&lt;h2 id="hobbies-">Hobbies ✨&lt;/h2>
&lt;p>I enjoy salsa dancing💃🏻, art and crafts🎨, trekking⛰️ and baking🍰! I play the guitar, and recently cleared the Trinity Grade 4: Rock n Pop Exam with merit🎸&lt;/p></content></item><item><title>Connect</title><link>/connect/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/connect/</guid><description>I am all about talking and sharing! Reach out to me to discuss anything Data, Ethics, Social Impact or just to say hi? 💼 LinkedIn 🖥️ GitHub 🕊️ Twitter</description><content>&lt;h4 id="i-am-all-about-talking-and-sharing-reach-out-to-me-to-discuss-anything-data-ethics-social-impact-or-just-to-say-hi">I am all about talking and sharing! Reach out to me to discuss anything Data, Ethics, Social Impact or just to say hi?&lt;/h4>
&lt;!-- raw HTML omitted -->
&lt;ul>
&lt;li>💼 &lt;a href="https://www.linkedin.com/in/bhairavi-muralidharan/">LinkedIn&lt;/a>&lt;/li>
&lt;li>🖥️ &lt;a href="https://github.com/bhairavi-m">GitHub&lt;/a>&lt;/li>
&lt;li>🕊️ &lt;a href="https://twitter.com/bayeasian">Twitter&lt;/a>&lt;/li>
&lt;/ul></content></item><item><title>Resume</title><link>/resume/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/resume/</guid><description/><content>&lt;script type="text/javascript" src= '/js/pdf-js/build/pdf.js'>&lt;/script>
&lt;link href="/fontawesome/css/all.min.css" rel="stylesheet">
&lt;style>
#embed-pdf-container {
position: relative;
width: 100%;
height: auto;
}
.pdf-canvas {
border: 1px solid black;
direction: ltr;
width: 100%;
height: auto;
display: none;
}
#loadingWrapper {
display: none;
justify-content: center;
align-items: center;
width: 100%;
height: 350px;
}
#loading {
display: inline-block;
width: 50px;
height: 50px;
border: 3px solid #d2d0d0;;
border-radius: 50%;
border-top-color: #383838;
animation: spin 1s ease-in-out infinite;
-webkit-animation: spin 1s ease-in-out infinite;
}
#overlayText > a:link{
color: steelblue;
}
#overlayText {
position: absolute;
word-wrap: break-word;
right: 5px;
top: 5px;
}
@keyframes spin {
to { -webkit-transform: rotate(360deg); }
}
@-webkit-keyframes spin {
to { -webkit-transform: rotate(360deg); }
}
&lt;/style>
&lt;div id="embed-pdf-container">
&lt;div id="loadingWrapper">
&lt;div id="loading">&lt;/div>
&lt;/div>
&lt;div id="overlayText">
&lt;a href="/resume.pdf" download>
&lt;i class="fas fa-download fa-2x">&lt;/i>
&lt;/a>
&lt;/div>
&lt;/div>
&lt;script type="text/javascript">
window.onload = function() {
var url = 'https:\/\/bhairavi-m.github.io\/resume.pdf';
console.log(url)
var pdfjsLib = window['pdfjs-dist/build/pdf'];
pdfjsLib.GlobalWorkerOptions.workerSrc = "\/" + '/js/pdf-js/build/pdf.worker.js';
var pdfDoc = null,
pageNum = 1,
pageRendering = false,
pageNumPending = null,
scale = 3,
loadingWrapper = document.getElementById('loadingWrapper');
showLoader();
function renderPage(num) {
pageRendering = true;
pdfDoc.getPage(num).then(function(page) {
var pdf_cont = document.getElementById('embed-pdf-container');
var canvas = getCanvas(num);
pdf_cont.appendChild(canvas);
var viewport = page.getViewport({scale: scale});
canvas.height = viewport.height;
canvas.width = viewport.width;
var ctx = canvas.getContext('2d');
var renderContext = {
canvasContext: ctx,
viewport: viewport
};
var renderTask = page.render(renderContext);
renderTask.promise.then(function() {
pageRendering = false;
showContent(canvas);
if (pageNumPending !== null) {
renderPage(pageNumPending);
pageNumPending = null;
}
});
});
}
function renderAllPages() {
for (var i = 1; i &lt;= pdfDoc.numPages; i++) {
renderPage(i);
}
}
function showContent(canvas) {
loadingWrapper.style.display = 'none';
canvas.style.display = 'block';
}
function showLoader() {
loadingWrapper.style.display = 'flex';
}
function queueRenderPage(num) {
if (pageRendering) {
pageNumPending = num;
} else {
renderPage(num);
}
}
function getCanvas(num) {
var canvasId = 'embed-pdf-container-' + num;
var canvas = document.createElement("canvas");
canvas.id = canvasId;
canvas.className = 'pdf-canvas';
return canvas
}
pdfjsLib.getDocument(url).promise.then(function(pdfDoc_) {
pdfDoc = pdfDoc_;
renderAllPages();
});
}
&lt;/script></content></item></channel></rss>